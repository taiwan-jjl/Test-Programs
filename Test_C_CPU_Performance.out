# of chained FMA is: 1
The number of threads is 32
Chained FMAs=1, vector width=8, GFLOPs=512.0, time=1.690316 s, performance=302.9 GFLOP/s
# of chained FMA is: 2
The number of threads is 32
Chained FMAs=2, vector width=8, GFLOPs=1024.0, time=1.691626 s, performance=605.3 GFLOP/s
# of chained FMA is: 3
The number of threads is 32
Chained FMAs=3, vector width=8, GFLOPs=1536.0, time=2.130897 s, performance=720.8 GFLOP/s
# of chained FMA is: 4
The number of threads is 32
Chained FMAs=4, vector width=8, GFLOPs=2048.0, time=2.128448 s, performance=962.2 GFLOP/s
# of chained FMA is: 5
The number of threads is 32
Chained FMAs=5, vector width=8, GFLOPs=2560.0, time=2.129494 s, performance=1202.2 GFLOP/s
# of chained FMA is: 6
The number of threads is 32
Chained FMAs=6, vector width=8, GFLOPs=3072.0, time=2.130534 s, performance=1441.9 GFLOP/s
# of chained FMA is: 7
The number of threads is 32
Chained FMAs=7, vector width=8, GFLOPs=3584.0, time=2.129608 s, performance=1682.9 GFLOP/s
# of chained FMA is: 8
The number of threads is 32
Chained FMAs=8, vector width=8, GFLOPs=4096.0, time=2.130546 s, performance=1922.5 GFLOP/s
# of chained FMA is: 9
The number of threads is 32
Chained FMAs=9, vector width=8, GFLOPs=4608.0, time=2.396069 s, performance=1923.1 GFLOP/s
# of chained FMA is: 10
The number of threads is 32
Chained FMAs=10, vector width=8, GFLOPs=5120.0, time=2.662412 s, performance=1923.1 GFLOP/s
# of chained FMA is: 11
The number of threads is 32
Chained FMAs=11, vector width=8, GFLOPs=5632.0, time=2.927552 s, performance=1923.8 GFLOP/s
# of chained FMA is: 12
The number of threads is 32
Chained FMAs=12, vector width=8, GFLOPs=6144.0, time=3.193440 s, performance=1923.9 GFLOP/s
# of chained FMA is: 13
The number of threads is 32
Chained FMAs=13, vector width=8, GFLOPs=6656.0, time=3.457342 s, performance=1925.2 GFLOP/s
# of chained FMA is: 14
The number of threads is 32
Chained FMAs=14, vector width=8, GFLOPs=7168.0, time=3.723104 s, performance=1925.3 GFLOP/s
# of chained FMA is: 15
The number of threads is 32
Chained FMAs=15, vector width=8, GFLOPs=7680.0, time=3.988783 s, performance=1925.4 GFLOP/s
# of chained FMA is: 16
The number of threads is 32
Chained FMAs=16, vector width=8, GFLOPs=8192.0, time=4.255786 s, performance=1924.9 GFLOP/s
# of chained FMA is: 17
The number of threads is 32
Chained FMAs=17, vector width=8, GFLOPs=8704.0, time=19.180041 s, performance=453.8 GFLOP/s
# of chained FMA is: 18
The number of threads is 32
Chained FMAs=18, vector width=8, GFLOPs=9216.0, time=20.295596 s, performance=454.1 GFLOP/s
# of chained FMA is: 19
The number of threads is 32
Chained FMAs=19, vector width=8, GFLOPs=9728.0, time=21.399396 s, performance=454.6 GFLOP/s
# of chained FMA is: 20
The number of threads is 32
Chained FMAs=20, vector width=8, GFLOPs=10240.0, time=22.493337 s, performance=455.2 GFLOP/s
